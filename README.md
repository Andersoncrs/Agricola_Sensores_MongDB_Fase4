# Práctica MongoDB
Este repositorio contiene el conjunto de scripts y consultas diseñados para la gestión de una base de datos NoSQL orientada a documentos, implementada en MongoDB. El proyecto simula un entorno de Big Data aplicado a la agricultura de precisión, donde la velocidad de escritura, la flexibilidad de los esquemas y la capacidad de análisis de grandes volúmenes de datos son críticos.

## Descripción del Caso de Uso
El proyecto se centra en resolver los desafíos que presenta el monitoreo de cultivos a gran escala mediante el Internet de las Cosas (IoT). En este escenario, cientos de sensores distribuidos en diferentes zonas geográficas generan mediciones constantes de variables como temperatura, humedad del suelo, luminosidad y pH. Las bases de datos relacionales tradicionales suelen presentar problemas de latencia y bloqueos de escritura ante tal flujo de datos, además de rigidez ante la variabilidad de la estructura de la información que envían distintos tipos de sensores.

Para solucionar esto, se ha implementado una arquitectura basada en MongoDB. Esta elección permite ingestar datos en formato JSON/BSON directamente desde los dispositivos sin transformaciones costosas, escalar horizontalmente y permitir que diferentes sensores reporten métricas distintas en una misma colección. El sistema está diseñado para centralizar la información de cuatro componentes principales: las Zonas de cultivo (ubicación y configuración ideal), los Dispositivos (inventario de sensores y actuadores), las Mediciones (historial de lecturas) y las Alertas (eventos críticos que requieren atención).

## Descripción de las Consultas Realizadas
El archivo de código incluido en este repositorio abarca tres fases fundamentales de la manipulación y análisis de datos en MongoDB, las cuales se describen a continuación:

1. Operaciones Básicas de Gestión (CRUD)
En esta primera etapa se establecen las interacciones fundamentales con la base de datos para garantizar la operatividad del sistema. Se comienza con la inserción de nuevos documentos, ejemplificado mediante el registro de una nueva zona de cultivo en el municipio de Zipaquirá. Posteriormente, se realizan consultas de selección para apoyar al equipo de mantenimiento, identificando aquellos sensores que se encuentran inactivos o en reparación. También se abordan las actualizaciones de datos, simulando la resolución de una alerta crítica por parte de un operario, y finalmente se procede a la eliminación de registros obsoletos, como es el caso de dispositivos dañados irremediablemente que deben ser retirados del inventario lógico.

2. Consultas Avanzadas con Filtros y Operadores
Para extraer valor real de los datos almacenados, se ejecutan consultas que permiten segmentar la información con gran precisión. Se utilizan operadores de comparación para filtrar mediciones de temperatura dentro de rangos específicos de crecimiento (por ejemplo, entre 20°C y 28°C), lo cual es vital para los agrónomos. Asimismo, se implementan filtros geográficos utilizando listas para ubicar zonas en municipios específicos como Facatativá, Jericó y Pitalito. Adicionalmente, se realizan búsquedas lógicas complejas para gestión de riesgos, identificando alertas críticas que aún no han sido resueltas o localizando dispositivos que requieren atención física inmediata, ya sea por su estado operativo o por pertenecer a lotes de fabricantes específicos que han presentado fallas.

3. Análisis de Datos y Agregaciones
La fase final se enfoca en la inteligencia de negocios y el análisis estadístico mediante el "Aggregation Framework" de MongoDB. A través de estas tuberías de procesamiento, se calcula la temperatura promedio registrada por cada sensor individual para detectar posibles descalibraciones. También se generan reportes de estado que contabilizan cuántos dispositivos están activos frente a los inactivos, ofreciendo una visión clara de la salud de la infraestructura. Se profundiza en el análisis ambiental obteniendo los valores extremos (mínimos y máximos) y promedios globales de humedad del suelo para descartar lecturas anómalas. Finalmente, se genera un ranking de las zonas más problemáticas, ordenándolas según la cantidad de alertas críticas acumuladas, lo que permite priorizar los recursos de intervención en las áreas que más lo necesitan.
